# 0.47h x 3 on RTX 2080 Ti
name: AttentionXML

model:
  hidden_size: 256
  layers_num: 1
  linear_size: [256]
  dropout: 0.5
  emb_trainable: False
  # load_model: true

train:
  batch_size: 40
  nb_epoch: 30
  swa_warmup: 10

valid:
  batch_size: 40

predict:
  batch_size: 40
  top_head_k: 30
  top_tail_k: 70

path: models
